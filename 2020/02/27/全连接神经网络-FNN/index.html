<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Bool_tbb" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="1import numpy as np">
<meta property="og:type" content="article">
<meta property="og:title" content="全连接神经网络-FNN">
<meta property="og:url" content="http://yoursite.com/2020/02/27/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-FNN/index.html">
<meta property="og:site_name" content="Bool_tbb">
<meta property="og:description" content="1import numpy as np">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2020/02/27/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-FNN/output_10_1.png">
<meta property="article:published_time" content="2020-02-27T09:34:02.000Z">
<meta property="article:modified_time" content="2022-03-28T09:04:28.990Z">
<meta property="article:author" content="bool_tbb">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/02/27/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-FNN/output_10_1.png">

<link rel="canonical" href="http://yoursite.com/2020/02/27/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-FNN/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>全连接神经网络-FNN | Bool_tbb</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<body itemscope itemtype="http://schema.org/WebPage">

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Bool_tbb</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">一枚NLPer小菜鸡</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/27/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-FNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/tb3.jpeg">
      <meta itemprop="name" content="bool_tbb">
      <meta itemprop="description" content="关于一些在NLP领域的学习总结，或者随便写点啥。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Bool_tbb">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          全连接神经网络-FNN
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-27 17:34:02" itemprop="dateCreated datePublished" datetime="2020-02-27T17:34:02+08:00">2020-02-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-03-28 17:04:28" itemprop="dateModified" datetime="2022-03-28T17:04:28+08:00">2022-03-28</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="comment">#该类为所有其他图节点类的父类</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,inputs=[])</span>:</span></span><br><span class="line">        <span class="comment">#定义每个节点的输入和输出</span></span><br><span class="line">        self.inputs = inputs</span><br><span class="line">        self.outputs = []</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#每个节点都是其输入节点的输出节点</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.inputs:</span><br><span class="line">            n.outputs.append(self)</span><br><span class="line">            <span class="comment"># set 'self' node as inbound_nodes's outbound_nodes</span></span><br><span class="line">            </span><br><span class="line">        self.value = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        self.gradients = &#123;&#125;</span><br><span class="line">        <span class="comment"># keys are the inputs to this node,and</span></span><br><span class="line">        <span class="comment">#their values are the partials of this node with</span></span><br><span class="line">        <span class="comment"># respect to that input.</span></span><br><span class="line">        <span class="comment"># \partial&#123;node&#125;&#123;input_i&#125;</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#前向传播函数，继承该类的其他类会覆写该函数</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Forward propagation.</span></span><br><span class="line"><span class="string">        Compute the output value based on 'inbound_nodes' and store the</span></span><br><span class="line"><span class="string">        result in self.value</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">raise</span> <span class="built_in">NotImplemented</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#反向传播函数，继承该类的其他类会覆写该函数</span></span><br><span class="line">        <span class="keyword">raise</span> <span class="built_in">NotImplemented</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Input</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="comment">#输入节点，包括神经网络输入节点，权重节点，和偏差节点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        An Input node has no inbound nodes,</span></span><br><span class="line"><span class="string">        So no need to pass anythinto the Node instantiator.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        Node.__init__(self)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, value=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Only input node is the node where the value may be passed</span></span><br><span class="line"><span class="string">        as anargument to forward().</span></span><br><span class="line"><span class="string">        All other node implementations should get the value of the </span></span><br><span class="line"><span class="string">        previous node from self.inbound_nodes</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Example:</span></span><br><span class="line"><span class="string">        val0:self.inbound_nodes[0].value</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment">#定义节点数值</span></span><br><span class="line">        <span class="keyword">if</span> value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.value =value</span><br><span class="line">            <span class="comment">#It's is input node,when need to forward,this node initiate</span></span><br><span class="line">            <span class="comment">#self's value.</span></span><br><span class="line">        <span class="comment"># Input subclass just holds a value,such as a data feature or</span></span><br><span class="line">        <span class="comment"># model parameter(weight/bias)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#计算节点梯度</span></span><br><span class="line">        self.gradients = &#123;self:<span class="number">0</span>&#125;<span class="comment"># initialization</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            <span class="comment">#以下计算该节点的输出节点对该节点的梯度</span></span><br><span class="line">            grad_cost = n.gradients[self]</span><br><span class="line">            self.gradients[self] =grad_cost*<span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># input --&gt; N1,N2</span></span><br><span class="line">            <span class="comment">#\partial L / \partial N</span></span><br><span class="line">            <span class="comment"># ==&gt; \partial L / partial N1 * \ partial N1 / \partial N</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Add</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,*nodes)</span>:</span></span><br><span class="line">        Node.__init__(self,nodes)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.value = sum(map(<span class="keyword">lambda</span> n:n.value,self.inputs))</span><br><span class="line">        <span class="comment"># when execute forward, this node cacultae value as defined</span></span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="comment">#全连接网络层的计算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,nodes,weights,bias)</span>:</span></span><br><span class="line">        Node.__init__(self,[nodes,weights,bias])</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#前向传播的计算 y=w*x + b</span></span><br><span class="line">        inputs = self.inputs[<span class="number">0</span>].value</span><br><span class="line">        weights = self.inputs[<span class="number">1</span>].value</span><br><span class="line">        bias = self.inputs[<span class="number">2</span>].value</span><br><span class="line">        </span><br><span class="line">        self.value =np.dot(inputs,weights) + bias</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#反向传播计算</span></span><br><span class="line">        <span class="comment"># initial a partial for each of the inbound_nodes.</span></span><br><span class="line">        self.gradients = &#123;n:np.zeros_like(n.value) <span class="keyword">for</span> n <span class="keyword">in</span> self.inputs&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            <span class="comment"># Get the partial of the cost w.r.t this node.</span></span><br><span class="line">            grad_cost = n.gradients[self]</span><br><span class="line">            </span><br><span class="line">            self.gradients[self.inputs[<span class="number">0</span>]] = np.dot(grad_cost,self.inputs[<span class="number">1</span>].value.T)</span><br><span class="line">            self.gradients[self.inputs[<span class="number">1</span>]] = np.dot(self.inputs[<span class="number">0</span>].value.T,grad_cost)</span><br><span class="line">            self.gradients[self.inputs[<span class="number">2</span>]] = np.sum(grad_cost,axis=<span class="number">0</span>,keepdims=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># WX + B / W ==&gt; X</span></span><br><span class="line">        <span class="comment"># WX + B / X ==&gt; W</span></span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sigmoid</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="comment">#定义sigmod函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,node)</span>:</span></span><br><span class="line">        Node.__init__(self,[node])</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span>/(<span class="number">1</span>+np.exp(<span class="number">-1</span>*x))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#前向 即sigmoid函数计算</span></span><br><span class="line">        self.x = self.inputs[<span class="number">0</span>].value <span class="comment"># [0] input is a list</span></span><br><span class="line">        self.value = self._sigmoid(self.x)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#反向传播计算梯度</span></span><br><span class="line">        self.partial = self._sigmoid(self.x) * (<span class="number">1</span> -self._sigmoid(self.x))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># y = 1/(1+ e^-x)</span></span><br><span class="line">        <span class="comment"># y'= 1/(1 + e^-x) (1 - 1/(1 + e^-x))</span></span><br><span class="line">        </span><br><span class="line">        self.gradients = &#123;n:np.zeros_like(n.value) <span class="keyword">for</span> n <span class="keyword">in</span> self.inputs&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            grad_cost = n.gradients[self] <span class="comment"># Get the partial of the cost with respect to this node</span></span><br><span class="line">            </span><br><span class="line">            self.gradients[self.inputs[<span class="number">0</span>]] = grad_cost * self.partial</span><br><span class="line">            <span class="comment"># use * to keep all the dimension same!.</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MSE</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="comment"># 定义平均平方误差</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,y,a)</span>:</span></span><br><span class="line">        Node.__init__(self,[y,a])</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#前向传播计算</span></span><br><span class="line">        y = self.inputs[<span class="number">0</span>].value.reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">        a = self.inputs[<span class="number">1</span>].value.reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">assert</span>(y.shape == a.shape)</span><br><span class="line">        </span><br><span class="line">        self.m = self.inputs[<span class="number">0</span>].value.shape[<span class="number">0</span>]</span><br><span class="line">        self.diff = y -a</span><br><span class="line">        </span><br><span class="line">        self.value = np.mean(self.diff**<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#反向计算相应的梯度</span></span><br><span class="line">        self.gradients[self.inputs[<span class="number">0</span>]] = ( <span class="number">2</span> / self.m) * self.diff</span><br><span class="line">        self.gradients[self.inputs[<span class="number">1</span>]] = ( <span class="number">-2</span> /self.m) * self.diff</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_and_backward</span><span class="params">(outputnode,graph)</span>:</span></span><br><span class="line">    <span class="comment"># execute all the forward method of sorted_nodes.</span></span><br><span class="line">    <span class="comment">## In practice,it's common to feed in mutiple data example in each forward pass rather than just 1. Because the example can be</span></span><br><span class="line">    <span class="comment">## processed in parallel.The number of examples is called batch size.</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> graph:</span><br><span class="line">        n.forward()</span><br><span class="line">        <span class="comment"># each node execute forward, get self.value based on the topological sort result.</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> graph[::<span class="number">-1</span>]:</span><br><span class="line">        n.backward()</span><br><span class="line">    <span class="comment"># return outputnode.value</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### v -&gt; a -&gt; C</span></span><br><span class="line"><span class="comment">##  b -&gt; C</span></span><br><span class="line"><span class="comment">##  b -&gt; v - a -&gt; C</span></span><br><span class="line"><span class="comment">## v -&gt; v -&gt; a -&gt; C</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">topological_sort</span><span class="params">(feed_dict)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Sort generic nodes in topological order using Kahn's Algorithm.</span></span><br><span class="line"><span class="string">    'feed_dict': A dictionary where the key is a 'Input' node and the value is the respective value feed to that node.</span></span><br><span class="line"><span class="string">    Returns a list of sorted nodes.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    input_nodes = [n <span class="keyword">for</span> n <span class="keyword">in</span> feed_dict.keys()]</span><br><span class="line">    </span><br><span class="line">    G = &#123;&#125;</span><br><span class="line">    nodes = [n <span class="keyword">for</span> n <span class="keyword">in</span> input_nodes]</span><br><span class="line">    <span class="keyword">while</span> len(nodes)&gt;<span class="number">0</span>:</span><br><span class="line">        n = nodes.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> n <span class="keyword">not</span> <span class="keyword">in</span> G:</span><br><span class="line">            G[n] = &#123;<span class="string">'in'</span>:set(),<span class="string">'out'</span>:set()&#125;</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> n.outputs:</span><br><span class="line">            <span class="keyword">if</span> m <span class="keyword">not</span> <span class="keyword">in</span> G:</span><br><span class="line">                G[m] = &#123;<span class="string">'in'</span>:set(),<span class="string">'out'</span>:set()&#125;</span><br><span class="line">            G[n][<span class="string">'out'</span>].add(m)</span><br><span class="line">            G[m][<span class="string">'in'</span>].add(n)</span><br><span class="line">            nodes.append(m)</span><br><span class="line">    </span><br><span class="line">    L =[]</span><br><span class="line">    S = set(input_nodes)</span><br><span class="line">    <span class="keyword">while</span> len(S) &gt;<span class="number">0</span>:</span><br><span class="line">        n = S.pop()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> isinstance(n,Input):</span><br><span class="line">            n.value= feed_dict[n]</span><br><span class="line">            <span class="comment">## if n is Input Node,setn'value as</span></span><br><span class="line">            <span class="comment">## feed_dict[n]</span></span><br><span class="line">            <span class="comment">## else, n's value is caculate as its</span></span><br><span class="line">            <span class="comment">## inbounds</span></span><br><span class="line">        L.append(n)</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> n.outputs:</span><br><span class="line">            G[n][<span class="string">'out'</span>].remove(m)</span><br><span class="line">            G[m][<span class="string">'in'</span>].remove(n)</span><br><span class="line">            <span class="comment"># if no other incoming edges add to S</span></span><br><span class="line">            <span class="keyword">if</span> len(G[m][<span class="string">'in'</span>]) == <span class="number">0</span>:</span><br><span class="line">                S.add(m)</span><br><span class="line">    <span class="keyword">return</span> L</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd_update</span><span class="params">(trainables,learning_rate =<span class="number">1e-2</span>)</span>:</span></span><br><span class="line">    <span class="comment">#there are so many other update / optimigation methods</span></span><br><span class="line">    <span class="comment">#such as Adam,Mom,</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> trainables:</span><br><span class="line">        t.value += <span class="number">-1</span> * learning_rate * t.gradients[t]</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\partial{node}{input_i}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = load_boston()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">losses = []</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Check out the new network architecture and dataset!</span></span><br><span class="line"><span class="string">Notice that the weights and biases are </span></span><br><span class="line"><span class="string">generated randomly.</span></span><br><span class="line"><span class="string">No need to change anything,but feel free to tweak</span></span><br><span class="line"><span class="string">to test your network, play around with the epoches, batch size,etc!</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.utils <span class="keyword">import</span> shuffle,resample</span><br><span class="line"><span class="comment">#from minflow import *</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Load data</span></span><br><span class="line">data =load_boston()</span><br><span class="line">X_ = data[<span class="string">'data'</span>]</span><br><span class="line">_ = data[<span class="string">'target'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize data</span></span><br><span class="line"></span><br><span class="line">X_ = (X_ - np.mean(X_,axis=<span class="number">0</span>)) / np.std(X_,axis =<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">n_features =X_.shape[<span class="number">1</span>]</span><br><span class="line">n_hidden = <span class="number">10</span></span><br><span class="line">W1_ = np.random.randn(n_features,n_hidden)</span><br><span class="line">b1_ = np.zeros(n_hidden)</span><br><span class="line">W2_ = np.random.randn(n_hidden,<span class="number">1</span>)</span><br><span class="line">b2_ = np.zeros(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Neural network</span></span><br><span class="line">X,y = Input(),Input()</span><br><span class="line">W1,b1=Input(),Input()</span><br><span class="line">W2,b2 =Input(),Input()</span><br><span class="line"></span><br><span class="line">l1 = Linear(X,W1,b1)</span><br><span class="line">s1 = Sigmoid(l1)</span><br><span class="line">l2 = Linear(s1,W2,b2)</span><br><span class="line">cost = MSE(y,l2)</span><br><span class="line"></span><br><span class="line">feed_dict = &#123;</span><br><span class="line">    X:X_,</span><br><span class="line">    y:y_,</span><br><span class="line">    W1:W1_,</span><br><span class="line">    b1:b1_,</span><br><span class="line">    W2:W2_,</span><br><span class="line">    b2:b2_</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">5000</span></span><br><span class="line"><span class="comment"># Total number of examples</span></span><br><span class="line">m = X_.shape[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">steps_per_epoch = m // batch_size</span><br><span class="line"></span><br><span class="line">graph = topological_sort(feed_dict)</span><br><span class="line">trainables = [W1,b1,W2,b2]</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Total number of examples = &#123;&#125;"</span>.format(m))</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 4</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epochs):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(steps_per_epoch):</span><br><span class="line">        <span class="comment"># Step 1</span></span><br><span class="line">        <span class="comment"># Randomly sample a batch of examples</span></span><br><span class="line">        X_batch,y_batch =resample(X_,y_,n_samples=batch_size)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Reset valueof X and y Inputs</span></span><br><span class="line">        X.value = X_batch</span><br><span class="line">        y.value = y_batch</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2</span></span><br><span class="line">        _ = <span class="literal">None</span></span><br><span class="line">        forward_and_backward(_,graph) <span class="comment">#set output node not important.</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 3</span></span><br><span class="line">        rate =<span class="number">1e-2</span></span><br><span class="line">        </span><br><span class="line">        sgd_update(trainables,rate)</span><br><span class="line">        </span><br><span class="line">        loss += graph[<span class="number">-1</span>].value</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Epoch:&#123;&#125;,Loss:&#123;:.3f&#125;"</span>.format(i+<span class="number">1</span>,loss/steps_per_epoch))</span><br><span class="line">        losses.append(loss)</span><br></pre></td></tr></table></figure>
<pre><code>Total number of examples = 506
Epoch:1,Loss:171.205
Epoch:101,Loss:8.215
Epoch:201,Loss:7.937
Epoch:301,Loss:7.301
Epoch:401,Loss:6.069
Epoch:501,Loss:5.735
Epoch:601,Loss:4.524
Epoch:701,Loss:4.418
Epoch:801,Loss:4.473
Epoch:901,Loss:4.510
Epoch:1001,Loss:3.484
Epoch:1101,Loss:4.627
Epoch:1201,Loss:4.473
Epoch:1301,Loss:4.152
Epoch:1401,Loss:4.831
Epoch:1501,Loss:4.992
Epoch:1601,Loss:4.500
Epoch:1701,Loss:4.706
Epoch:1801,Loss:3.927
Epoch:1901,Loss:4.712
Epoch:2001,Loss:4.262
Epoch:2101,Loss:3.968
Epoch:2201,Loss:4.792
Epoch:2301,Loss:4.106
Epoch:2401,Loss:3.815
Epoch:2501,Loss:4.089
Epoch:2601,Loss:4.376
Epoch:2701,Loss:3.923
Epoch:2801,Loss:5.195
Epoch:2901,Loss:4.273
Epoch:3001,Loss:3.618
Epoch:3101,Loss:3.368
Epoch:3201,Loss:3.754
Epoch:3301,Loss:4.027
Epoch:3401,Loss:3.442
Epoch:3501,Loss:4.029
Epoch:3601,Loss:3.475
Epoch:3701,Loss:3.861
Epoch:3801,Loss:4.248
Epoch:3901,Loss:3.697
Epoch:4001,Loss:4.466
Epoch:4101,Loss:4.746
Epoch:4201,Loss:4.145
Epoch:4301,Loss:3.594
Epoch:4401,Loss:4.501
Epoch:4501,Loss:3.719
Epoch:4601,Loss:4.005
Epoch:4701,Loss:4.331
Epoch:4801,Loss:4.092
Epoch:4901,Loss:3.657
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(outputNode,graph)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> graph:</span><br><span class="line">        n.forward()</span><br><span class="line">    <span class="keyword">return</span> outputNode.value</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">forward(l2,graph)</span><br></pre></td></tr></table></figure>
<pre><code>array([[18.41675144],
       [29.47806568],
       [15.32327987],
       [48.89022023],
       [49.92947466],
       [45.52560889],
       [30.32152378],
       [13.889439  ],
       [20.52297098],
       [38.29474339],
       [19.54218589],
       [10.72223761],
       [10.13966276],
       [19.20474889],
       [ 9.715787  ],
       [26.87621257]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(range(len(losses)),losses)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x1fd125539c8&gt;]
</code></pre><p><img src="output_10_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">W2.value</span><br></pre></td></tr></table></figure>
<pre><code>array([[3.78502026],
       [5.48520715],
       [6.6856144 ],
       [5.89625598],
       [5.81552044],
       [3.22412022],
       [8.54504219],
       [2.76550267],
       [9.40747634],
       [5.60113079]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_ = data[<span class="string">'data'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,
       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,
       4.980e+00])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line">model =Sequential()</span><br><span class="line"></span><br><span class="line">model.add(Dense(units = <span class="number">64</span>,activation=<span class="string">'sigmoid'</span>,input_dim=<span class="number">13</span>))</span><br><span class="line">model.add(Dense(units = <span class="number">30</span>,activation=<span class="string">'sigmoid'</span>,input_dim=<span class="number">64</span>))</span><br><span class="line">model.add(Dense(units=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">model.compile(loss = <span class="string">'mse'</span>,optimizer=<span class="string">'sgd'</span>,metrics = [<span class="string">'mse'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_,y_,epochs=<span class="number">5000</span>,batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/5000
506/506 [==============================] - 1s 3ms/step - loss: 158.0243 - mse: 158.0243
Epoch 2/5000
506/506 [==============================] - 0s 91us/step - loss: 81.3887 - mse: 81.3887
Epoch 3/5000
506/506 [==============================] - 0s 87us/step - loss: 79.5072 - mse: 79.5072
Epoch 4/5000
506/506 [==============================] - 0s 
Epoch 2700/5000
506/506 [==============================] - 0s 99us/step - loss: 85.0554 - mse: 85.0554
Epoch 2701/5000
506/506 [==============================] - 0s 142us/step - loss: 84.8442 - mse: 84.8442
Epoch 2702/5000
506/506 [==============================] - 0s 103us/step - loss: 85.1862 - mse: 85.1862
Epoch 2703/5000
506/506 [==============================] - 0s 97us/step - loss: 84.6198 - mse: 84.6198
Epoch 2704/5000
506/506 [==============================] - 0s 89us/step - loss: 85.3531 - mse: 85.3531
Epoch 2705/5000
506/506 [==============================] - 0s 101us/step - loss: 84.8638 - mse: 84.8638
Epoch 2706/5000
506/506 [==============================] - 0s 87us/step - loss: 84.6398 - mse: 84.6398
Epoch 2707/5000
506/506 [==============================] - 0s 154us/step - loss: 84.8038 - mse: 84.8038
Epoch 2708/5000
506/506 [==============================] - 0s 99us/step - loss: 84.6299 - mse: 84.6299
Epoch 2709/5000
506/506 [==============================] - 0s 101us/step - loss: 84.8330 - mse: 84.8330
Epoch 2710/5000
506/506 [==============================] - 0s 130us/step - loss: 85.0682 - mse: 85.0682
Epoch 2711/5000
506/506 [==============================] - 0s 111us/step - loss: 84.6372 - mse: 84.6372
Epoch 2712/5000
506/506 [==============================] - 0s 101us/step - loss: 84.6715 - mse: 84.6715
Epoch 2713/5000
506/506 [==============================] - 0s 128us/step - loss: 85.0228 - mse: 85.0228
Epoch 2714/5000
506/506 [==============================] - 0s 93us/step - loss: 84.8349 - mse: 84.8349
Epoch 2715/5000
506/506 [==============================] - 0s 109us/step - loss: 84.7732 - mse: 84.7732
Epoch 2716/5000
506/506 [==============================] - 0s 113us/step - loss: 84.7862 - mse: 84.7862
Epoch 2717/5000
506/506 [==============================] - 0s 113us/step - loss: 84.5297 - mse: 84.5297
Epoch 2718/5000
506/506 [==============================] - 0s 107us/step - loss: 84.7425 - mse: 84.7425
Epoch 2719/5000
506/506 [==============================] - 0s 103us/step - loss: 85.2987 - mse: 85.2987
Epoch 2720/5000
506/506 [==============================] - 0s 107us/step - loss: 84.6666 - mse: 84.6666
Epoch 2721/5000
506/506 [==============================] - 0s 103us/step - loss: 
506/506 [==============================] - 0s 105us/step - loss: 85.1947 - mse: 85.1947
Epoch 3139/5000
506/506 [==============================] - 0s 97us/step - loss: 84.9491 - mse: 84.9491
Epoch 3140/5000
506/506 [==============================] - 0s 99us/step - loss: 85.3199 - mse: 85.3198
Epoch 3141/5000
 32/506 [&gt;.............................] - ETA: 0s - loss: 114.7459 - mse: 114.7459
</code></pre>
    </div>

    
    
    
        <div class="reward-container">
  <div>O(∩_∩)O哈哈~</div>
  <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="bool_tbb 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="bool_tbb 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/01/31/Machinglearing-Model-the-first-step/" rel="next" title="Machinglearing Model,the first step">
                  <i class="fa fa-chevron-left"></i> Machinglearing Model,the first step
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/02/27/PdfMiner%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90/" rel="prev" title="PdfMiner文档解析">
                  PdfMiner文档解析 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="bool_tbb"
      src="/images/tb3.jpeg">
  <p class="site-author-name" itemprop="name">bool_tbb</p>
  <div class="site-description" itemprop="description">关于一些在NLP领域的学习总结，或者随便写点啥。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">21</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/iiot-tbb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;iiot-tbb" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/bool_tbb@sjtu.edu.cn" title="E-Mail → bool_tbb@sjtu.edu.cn"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/5313762851" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;5313762851" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/16817976/bool-tbb" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;16817976&#x2F;bool-tbb" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      推荐阅读
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://developer.apple.com/swift/" title="https:&#x2F;&#x2F;developer.apple.com&#x2F;swift&#x2F;" rel="noopener" target="_blank">Swift 4</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://developer.apple.com/documentation/objectivec" title="https:&#x2F;&#x2F;developer.apple.com&#x2F;documentation&#x2F;objectivec" rel="noopener" target="_blank">Objective -C</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

      
      <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
      <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
      <div class="widget-wrap">
          <h3 class="widget-title">Tag Cloud</h3>
          <div id="myCanvasContainer" class="widget tagcloud">
              <canvas width="250" height="250" id="resCanvas" style="width=100%">
                  <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/" rel="tag">AI</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Autograd/" rel="tag">Autograd</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dialog/" rel="tag">Dialog</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Grammar-Inuduction/" rel="tag">Grammar Inuduction</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Languaage-Model/" rel="tag">Languaage Model</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Language-Model/" rel="tag">Language Model</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PDF%E8%A7%A3%E6%9E%90/" rel="tag">PDF解析</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Parameter-Efficient/" rel="tag">Parameter Efficient</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Syntax-Tree/" rel="tag">Syntax-Tree</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crf/" rel="tag">crf</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dialog-system/" rel="tag">dialog system</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/knowledge-base/" rel="tag">knowledge base</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/myBorn/" rel="tag">myBorn</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nlp/" rel="tag">nlp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/" rel="tag">numpy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/open-domain/" rel="tag">open domain</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" rel="tag">二叉树</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%BA%E6%96%87/" rel="tag">人文</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B3%95%E5%BE%8B/" rel="tag">法律</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag">自然语言处理</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%8F%E7%AC%94/" rel="tag">随笔</a><span class="tag-list-count">1</span></li></ul>
              </canvas>
          </div>
      </div>
      
      
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bool_tbb</span>
</div>
  <div class="powered-by">由 <a href="https://github.com/iiot-tbb" class="theme-link" rel="noopener" target="_blank">Tbb</a> 强力驱动 v1.0.0
  </div>
  <span class="post-meta-divider">|</span>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共50k字</span>
</div>


<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("11/11/2019 12:49:25");//在此处修改你的建站时间
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = " 运行了 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>














  

  

  

  
<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
